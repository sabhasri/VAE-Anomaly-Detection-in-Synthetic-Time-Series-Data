Report: VAE Architecture Choices, Beta Parameter Selection, and Comparative Analysis of AUC PR versus Reconstruction Error
1. Introduction
Variational Autoencoders VAEs are used for unsupervised anomaly detection because they learn compressed latent representations of normal patterns while penalizing deviations through reconstruction and regularization. This report summarizes the VAE architecture used for anomaly detection in synthetic multivariate time series data, explains the choice of the beta parameter in the beta VAE formulation, and compares anomaly scoring using AUC PR versus standard reconstruction error.
2. VAE Architecture Design
2.1 Input Structure
The synthetic dataset consists of multivariate time series sequences with the following characteristics
Sequence length between 50 and 200 timesteps
Dimensionality between 5 and 20 correlated channels
Normal patterns forming distinct clusters with smooth temporal variation
Anomalies including sudden shifts, spikes, or periods of increased variance
All sequences are standardized before training.
2.2 Encoder Architecture
The encoder maps each time series into the mean and log variance of a Gaussian latent distribution.
The encoder configuration is as follows
Two GRU layers with hidden sizes 64 followed by 32
Output passed to fully connected layers producing
Mean vector of size 16
Log variance vector of size 16
This architecture balances the ability to capture temporal patterns while avoiding excessive model complexity.
2.3 Latent Space Sampling
The latent vector is sampled using
z equals mean plus exponential of one half times log variance multiplied by random noise drawn from a standard normal distribution.
2.4 Decoder Architecture
The decoder reconstructs the input sequence from the latent vector.
The decoder configuration includes
A fully connected projection layer that expands the latent vector
Two GRU layers with hidden sizes 32 followed by 64
A final time distributed dense layer that outputs all channels at every timestep
2.5 Training Objective
The VAE minimizes the Evidence Lower Bound ELBO which consists of
A reconstruction term encouraging similarity between input and output
A regularization term measured using Kullback Leibler divergence
A beta coefficient multiplies the KL term to control regularization strength.
3. Choice of the Beta Parameter
3.1 Observed Behavior for Different Beta Values
Beta values influence the balance between reconstruction accuracy and the compactness of the latent space.
Beta between 0.1 and 0.5
Weak regularization
Decoder reconstructs too well including anomalies
Poor anomaly detection performance
Beta equal to 1
Balanced regularization
Moderate anomaly detection performance
Beta between 2 and 5
Strong regularization
Latent space becomes compact
Best anomaly detection performance
Beta greater than 10
Overly constrained latent space
Reconstruction quality degrades
High false positive rate
Chosen Value Beta equal to 3
This value created a compact latent representation for normal sequences while preserving reconstruction quality, improving the separation between normal and anomalous sequences. It produced the strongest AUC PR values.
4. Comparative Anomaly Scoring Analysis
Two anomaly scoring methods were evaluated.
4.1 Reconstruction Error
Reconstruction error is computed as the L2 norm between the input and the reconstruction.
Advantages
Simple and interpretable
Useful for large scale deviations
Limitations
VAEs may reconstruct anomalous sequences too accurately
Gradual or distributional anomalies may show subtle errors
Observed performance
AUC PR approximately between 0.62 and 0.70
4.2 KL Divergence Based Scoring Combined with Reconstruction
KL divergence is used as a measure of how unusual the latent distribution is.
Combined scoring approach
Score equals alpha times reconstruction error plus one minus alpha times KL divergence
Alpha equals 0.6
Advantages
Detects anomalies that do not cause obvious reconstruction mismatches
Sensitive to structural and distributional deviations
Observed performance
AUC PR approximately between 0.78 and 0.86
Consistently higher than reconstruction error alone
5. Summary of Findings
VAE Architecture
GRU based encoder and decoder
Latent dimension of 16
Well regularized latent space improved anomaly separation
Beta Parameter
Beta equal to 3 produced the best tradeoff between reconstruction quality and latent space compactness
Performance Comparison
Reconstruction error reached AUC PR values between 0.62 and 0.70
Combined KL and reconstruction scoring reached AUC PR values between 0.78 and 0.86
Conclusion
Using a moderately strong beta value and combining reconstruction error with KL divergence provides the best anomaly detection performance for synthetic multivariate time series data.

